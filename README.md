# ğŸ§  Research Copilot

**Research Copilot** is an **agentic literature analysis system** that automates the journey from raw research papers to structured insights, synthesis, and critique using Large Language Models (LLMs).

It is built to help researchers, students, and engineers **rapidly understand a research area**, identify trends, gaps, and evaluate the quality of synthesized conclusions.

---

## âœ¨ What This Project Does

Given a research topic, Research Copilot:

1. ğŸ” Searches arXiv for relevant papers  
2. ğŸ“„ Downloads and parses PDFs  
3. ğŸ§  Extracts structured metadata using an LLM agent  
4. ğŸ§© Synthesizes insights across papers  
5. ğŸ§ª Critiques the synthesis using a Critic Agent  
6. ğŸ–¥ï¸ Visualizes everything in a Streamlit UI  

All stages are **modular, inspectable, and agent-driven**.

---

## ğŸ—ï¸ Architecture Overview

Topic
â”‚
â–¼
[ arXiv Ingestion ]
â”‚
â–¼
[ PDF Parsing ]
â”‚
â–¼
[ Extraction Agent ]
â”‚   â†’ task, method, datasets, metrics, results, limitations
â–¼
[ Synthesis Agent ]
â”‚   â†’ trends, dominant tasks, gaps, open questions
â–¼
[ Critic Agent ]
â†’ strengths, weaknesses, rating, suggested repairs

Each agent runs independently and writes outputs to **disk** and **SQLite**.

---

## ğŸ¤– Agents

### ğŸ” Extraction Agent
Reads parsed paper sections and produces structured JSON:
- task
- method
- datasets
- metrics
- key results
- limitations

### ğŸ§  Synthesis Agent
Aggregates extractions to identify:
- dominant research directions
- common metrics and datasets
- gaps and open problems

### ğŸ§ª Critic Agent
Evaluates synthesis quality and outputs:
- overall rating (out of 10)
- strengths & weaknesses
- suggested repairs
- improved synthesis draft

---

## ğŸ–¥ï¸ Streamlit UI

The Streamlit app provides:

- ğŸš€ One-click pipeline execution
- ğŸ“„ Browse extracted papers
- ğŸ§  View synthesis outputs
- ğŸ§ª Inspect critic feedback
- ğŸ“œ Live pipeline logs

Run it with:

```bash
python -m streamlit run app/ui/streamlit_app.py


â¸»

âš™ï¸ Tech Stack

Core
	â€¢	Python 3.10+
	â€¢	SQLite
	â€¢	Streamlit

LLMs
	â€¢	Ollama (local models like mistral)
	â€¢	Gemini (optional, higher-quality synthesis & critique)

Parsing & Ingestion
	â€¢	PyMuPDF (PDF parsing)
	â€¢	feedparser (arXiv API)

â¸»

ğŸ“ Project Structure

research-copilot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â”œâ”€â”€ extraction_agent.py
â”‚   â”‚   â”œâ”€â”€ synthesis_agent.py
â”‚   â”‚   â””â”€â”€ critic_agent.py
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ run_extraction.py
â”‚   â”‚   â”œâ”€â”€ run_synthesis.py
â”‚   â”‚   â”œâ”€â”€ run_critic.py
â”‚   â”‚   â””â”€â”€ run_full_pipeline.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ parsing/
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ streamlit_app.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pdfs/
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ extracted/
â”‚   â”œâ”€â”€ synthesis/
â”‚   â””â”€â”€ critic/
â”œâ”€â”€ research.db
â”œâ”€â”€ .env.example
â””â”€â”€ README.md


â¸»

ğŸ” Configuration

Environment variables are required.
Never commit .env files.

Create one locally:

cp .env.example .env

Example:

LLM_PROVIDER=ollama
OLLAMA_MODEL=mistral
OLLAMA_URL=http://localhost:11434

GEMINI_API_KEY=your_key_here
CRITIC_PROVIDER=gemini

DB_PATH=research.db


â¸»

ğŸ§ª Run Full Pipeline (CLI)

python -m app.pipelines.run_full_pipeline

The Streamlit UI internally calls the same pipeline.

â¸»

ğŸ§  Is This RAG?

No â€” intentionally.

This is an agentic analysis pipeline, not a retrieval-augmented QA system.

RAG can be added later in parallel (e.g., â€œAsk questions over extracted sectionsâ€), but the core value here is structured reasoning across papers, not just answering queries.

â¸»

ğŸš§ Known Limitations (v1)
	â€¢	arXiv API rate limiting
	â€¢	Occasional LLM JSON formatting errors
	â€¢	No embedding / RAG layer yet

These are design-acknowledged, not architectural blockers.

â¸»

ğŸš€ Future Work
	â€¢	Parallel RAG pipeline
	â€¢	Embeddings over extracted sections
	â€¢	Topic clustering & comparison
	â€¢	Report export (Markdown / LaTeX)
	â€¢	Cloud deployment

â¸»

ğŸ¯ Why This Project Matters

Most tools say:

â€œHere are some papers.â€

Research Copilot says:

â€œHereâ€™s what this field is doing, how itâ€™s evaluated, where itâ€™s weak â€” and how good this synthesis actually is.â€

This is research sensemaking, not search.

â¸»

ğŸ‘¤ Author

Deepanshu Dawande
MSc Data Science & AI
Agentic Systems Â· LLM Evaluation Â· Applied ML
